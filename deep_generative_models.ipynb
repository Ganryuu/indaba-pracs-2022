{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# **Deep Generative Models**\n",
        "\n",
        "<img src=\"https://hojonathanho.github.io/diffusion/assets/img/denoising_diffusion_all.png\" width=\"60%\" />\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2022/blob/main/Indaba_2022_Prac_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> [Change colab link to point to prac.]\n",
        "\n",
        "¬© Deep Learning Indaba 2022. Apache License 2.0.\n",
        "\n",
        "**Authors:** James Allingham **[, Add yourself!]**\n",
        "\n",
        "Adapted from and inspired by [The Annotated Diffusion Model ü§ó](https://huggingface.co/blog/annotated-diffusion).\n",
        "\n",
        "**Introduction:** \n",
        "\n",
        "In this practical, we will investigate the fundamentals of generative modeling ‚Äì a machine learning framework that allows us to learn how to sample new unseen data points that match the distribution of our training dataset. Generative modeling, though a powerful and flexible framework‚Äìwhich has provided many exciting advances in ML‚Äìhas its own challenges and limitations. This practical will walk you through such challenges and will illustrate how to solve them by implementing a Denoising Diffusion Model (a.k.a. a Score-Based Generative Model), which is the backbone of the recent and exciting [Dalle-2](https://openai.com/dall-e-2/) and [Imagen](https://imagen.research.google/) models that we‚Äôve all seen on [Twitter](https://twitter.com/search?q=%23dalle2%20%23imagen&src=typed_query).\n",
        "\n",
        "**Topics:** \n",
        "\n",
        "Content: <font color='blue'>`Generative Models`</font>, <font color='red'>`Probabilistic Graphical Models`</font> \n",
        "\n",
        "Level: Advanced.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Aims/Learning Objectives:**\n",
        "\n",
        "\n",
        "* Understand the differences between generative and discriminative modeling.\n",
        "* Understand how the probabilistic approach to ML is key to generative modeling.\n",
        "* Understand the challenges of building generative models in practice, as well as their solutions.\n",
        "* Understand, implement, and train a Denoising Diffusion Model.\n",
        "\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "* Familiarity with Jax and Haiku ‚Äì going through the ‚ÄúIntroduction to ML using Jax‚Äù practical is **strongly** recommended.\n",
        "* Neural network basics (e.g., what ResNet, BatchNorm, and Adam are).\n",
        "<!-- * Basic linear algebra. -->\n",
        "* Basic probability theory (e.g., what a probability distribution is, what Bayes‚Äô rule is).\n",
        "* [Suggested] Attend the Monte Carlo 101 parallel ‚Äì this session will provide a lot of background on probability theory.\n",
        "\n",
        "**Outline:** \n",
        "\n",
        "[Points that link to each section. Auto-generate following the instructions [here](https://stackoverflow.com/questions/67458990/how-to-automatically-generate-a-table-of-contents-in-colab-notebook).]\n",
        "\n",
        "**Before you start:**\n",
        "\n",
        "For this practical, you will need to use a GPU to speed up training. To do this, go to the \"Runtime\" menu in Colab, select \"Change runtime type\" and then in the popup menu, choose \"GPU\" in the \"Hardware accelerator\" box.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EqhIg1odqg0"
      },
      "source": [
        "## Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4boGA9rYdt9l"
      },
      "outputs": [],
      "source": [
        "## Install and import anything required. Capture hides the output from the cell. \n",
        "#@title Install and import required packages. (Run Cell)\n",
        "\n",
        "!pip install dm-haiku\n",
        "!pip install optax\n",
        "!pip install distrax\n",
        "!pip install einops\n",
        "\n",
        "import os \n",
        "\n",
        "# https://stackoverflow.com/questions/68340858/in-google-colab-is-there-a-programing-way-to-check-which-runtime-like-gpu-or-tpu\n",
        "if int(os.environ[\"COLAB_GPU\"]) > 0:\n",
        "  print(\"a GPU is connected.\")\n",
        "elif \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "  print(\"A TPU is connected.\")\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "else:\n",
        "  print(\"Only CPU accelerator is connected.\")\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import haiku as hk\n",
        "import optax\n",
        "import distrax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "from einops import rearrange\n",
        "from opt_einsum import contract\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9X10jhocGaS"
      },
      "outputs": [],
      "source": [
        "#@title Helper Functions. (Run Cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rfwoGkW3cLuk"
      },
      "outputs": [],
      "source": [
        "#@title Check what device you are using (Run Cell)\n",
        "print(f\"Num devices: {jax.device_count()}\")\n",
        "print(f\" Devices: {jax.devices()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZUp8i37dFbU"
      },
      "source": [
        "## **Sample Section 1**\n",
        "\n",
        "[Background/content for the section.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii__Bc27epiJ"
      },
      "source": [
        "### Subsection - <font color='blue'>`Beginner`</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PbcFsfAibBu"
      },
      "source": [
        "Math foundations:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axeZiGJxibBw"
      },
      "source": [
        "**Math Task:**\n",
        "\n",
        "[Optional math task or ask multiple choice question. E.g. the derivation of this would equal a, b or c. We could check this at the end of the prac.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCURjj1HkQkW"
      },
      "outputs": [],
      "source": [
        "selection = 'a' #@param [\"a\", \"b\", \"c\"]\n",
        "print(f\"You selected: {selection}\")\n",
        "\n",
        "correct_answer = \"a\"\n",
        "assert selection == correct_answer, \"Incorrect answer, hint ...\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvbKqrRniVDa"
      },
      "source": [
        "Code demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNQ8Dgx2Wl8Q"
      },
      "outputs": [],
      "source": [
        "# Code demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jukLIz2oeiq9"
      },
      "source": [
        "**Code Task:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFXVVGa6elwN"
      },
      "outputs": [],
      "source": [
        "# Code to be implemented during practical\n",
        "# You should prove the function signature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDq7CAcAd49i"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhIkaajyaYGl"
      },
      "source": [
        "**Group Task:**\n",
        "\n",
        "Task that involves asking your neighbour or a group a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd7xAVznfBQU"
      },
      "source": [
        "### Subsection - <font color='orange'>`Intermediate`</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWlwCNlqfBQV"
      },
      "source": [
        "Math foundations:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YcpW8yAfBQW"
      },
      "source": [
        "**Math Task:**\n",
        "\n",
        "[Optional math task or ask multiple choice question. E.g. the derivation of this would equal a, b or c. We could check this at the end of the prac.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nyvX-3OJfBQW"
      },
      "outputs": [],
      "source": [
        "selection = 'a' #@param [\"a\", \"b\", \"c\"]\n",
        "print(f\"You selected: {selection}\")\n",
        "\n",
        "correct_answer = \"a\"\n",
        "assert selection == correct_answer, \"Incorrect answer, hint ...\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsUbInznfBQX"
      },
      "source": [
        "Code demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH-P90ULfBQY"
      },
      "outputs": [],
      "source": [
        "# Code demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQJtf6sCfBQY"
      },
      "source": [
        "**Code Task:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LICrxTN5fBQZ"
      },
      "outputs": [],
      "source": [
        "# Code to be implemented during practical\n",
        "# You should prove the function signature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE1YNtLkfBQZ"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZe6TDuNfBQa"
      },
      "source": [
        "**Group Task:**\n",
        "\n",
        "Task that involves asking your neighbour or a group a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SrT6swYgCm9"
      },
      "source": [
        "### Subsection - <font color='green'>`Advanced`</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYV9_wJcgCm-"
      },
      "source": [
        "Math foundations:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tWFVqp-gCm_"
      },
      "source": [
        "**Math Task:**\n",
        "\n",
        "[Optional math task or ask multiple choice question. E.g. the derivation of this would equal a, b or c. We could check this at the end of the prac.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bWAPYvKvgCm_"
      },
      "outputs": [],
      "source": [
        "selection = 'a' #@param [\"a\", \"b\", \"c\"]\n",
        "print(f\"You selected: {selection}\")\n",
        "\n",
        "correct_answer = \"a\"\n",
        "assert selection == correct_answer, \"Incorrect answer, hint ...\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-sxMredgCnA"
      },
      "source": [
        "Code demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B13f7D9SgCnB"
      },
      "outputs": [],
      "source": [
        "# Code demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHVQdNtqgCnB"
      },
      "source": [
        "**Code Task:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAGSVE4igCnC"
      },
      "outputs": [],
      "source": [
        "# Code to be implemented during practical\n",
        "# You should prove the function signature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTppRxGlgCnC"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q7WqzAVgCnD"
      },
      "source": [
        "**Group Task:**\n",
        "\n",
        "Task that involves asking your neighbour or a group a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7N-PXjlgkAd"
      },
      "source": [
        "### Subsection - <font color='purple'>`Optional`</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXDPiQMHgkAe"
      },
      "source": [
        "Math foundations:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGEzmGEkgkAe"
      },
      "source": [
        "**Math Task:**\n",
        "\n",
        "[Optional math task or ask multiple choice question. E.g. the derivation of this would equal a, b or c. We could check this at the end of the prac.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kbeCT6qfgkAf"
      },
      "outputs": [],
      "source": [
        "selection = 'a' #@param [\"a\", \"b\", \"c\"]\n",
        "print(f\"You selected: {selection}\")\n",
        "\n",
        "correct_answer = \"a\"\n",
        "assert selection == correct_answer, \"Incorrect answer, hint ...\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgccgCDjgkAg"
      },
      "source": [
        "Code demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uk14cnTgkAh"
      },
      "outputs": [],
      "source": [
        "# Code demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IHFxhVWgkAi"
      },
      "source": [
        "**Code Task:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVP_4c03gkAi"
      },
      "outputs": [],
      "source": [
        "# Code to be implemented during practical\n",
        "# You should prove the function signature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjZqw2z0gkAj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVw9C8GugkAj"
      },
      "source": [
        "**Group Task:**\n",
        "\n",
        "Task that involves asking your neighbour or a group a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WILOYJH4gCnD"
      },
      "source": [
        "### Section Quiz \n",
        "\n",
        "Optional end of section quiz. Below is an example of an assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5iFeOKOgCnE"
      },
      "outputs": [],
      "source": [
        "#@title Generate Quiz Form. (Run Cell)\n",
        "from IPython.display import HTML\n",
        "HTML(\n",
        "\"\"\"\n",
        "<iframe \n",
        "\tsrc=\"https://forms.gle/zbJoTSz3nfYq1VrY6\",\n",
        "  width=\"80%\" \n",
        "\theight=\"1200px\" >\n",
        "\tLoading...\n",
        "</iframe>\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l9pxSIRyhcHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep Generative Models**"
      ],
      "metadata": {
        "id": "Af0Sqm95helK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[Optional] Quick Probability Refreasher ‚Äì The Sum, Product, and Bayes' rules**"
      ],
      "metadata": {
        "id": "M0xpQUsjlfnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In probability theory there are 3 fundamental rules that come up over and over again. So let's quickly recap them if they aren't at the tip of your mind. \n",
        "\n",
        "1. **The Product Rule:** $$p(x, y) = p(x|y)p(y) = p(y|x)p(x), $$ tells us that the joint probability distribution over two random variables ($x$ and $y$ in this example) is equal to the product of the probability distribution for one of those random variables (e.g., $p(x)$) multiplied by the conditional probability distribution of the second random variable given the first (e.g., $p(y|x)$). \n",
        "\n",
        "2. **The Sum Rule:** $$p(x) = \\sum_y p(x,y), $$ tells us that we can sum over (or marginalise) a random variable ($y$ in this example) in a joint probability distribution in order to get a distribution over the remaining random variable(s) ($x$ in this example). In the case of a continuous distribution, the sum $\\sum$ would be replaced by an integral $\\int$.\n",
        "\n",
        "3. **Bayes' Rule:** $$p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$ tells us how to convert between conditional distributions. That is, if we have $p(x|y)$ (as well as $p(x)$ and $p(y)$) we can convert it to $p(y|x))$ and vice-versa. \n",
        "\n"
      ],
      "metadata": {
        "id": "mysbA0sIhXdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: add intuition, discussion point, etc."
      ],
      "metadata": {
        "id": "EQaoEMGOBKaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **[Optional] Math Task**"
      ],
      "metadata": {
        "id": "rVHXcVWDljxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes' rule can actually be derived from only the product rule. Test your understanding by trying to derive it yourself (or with your neighbours)! \n",
        "\n",
        "BONUS task: Go one step further and use the sum rule to write Bayes' rule without $p(x)$."
      ],
      "metadata": {
        "id": "j4HPhXjXl78I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Answer to the math task (Try not to peek until you've given it a good try!') \n"
      ],
      "metadata": {
        "id": "T6UsuU1ImRTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "p(x, y) & = p(y|x)p(x) && \\triangleright \\text{product rule}\\\\\n",
        "\\therefore p(y|x) &= \\frac{p(x, y)}{p(x)} \\\\\n",
        "&= \\frac{p(x|y)p(y)}{p(x)} && \\triangleright \\text{product rule}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "uzb72WYQpqGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Answer to BONUS math task (Try not to peek until you've given it a good try!') "
      ],
      "metadata": {
        "id": "v5OB2KDJp3hR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "p(y|x) &= \\frac{p(x|y)p(y)}{p(x)} \\\\\n",
        "&= \\frac{p(x|y)p(y)}{\\sum_y p(x|y)p(y)}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "AU50q93xqSSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is Generative Modeling?**"
      ],
      "metadata": {
        "id": "0mfHQOmE4Agg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way that machine learning methods can be categorised is by whether they are *discriminative* or *generative*. Some of the most common machine learning tasks, such as regression and classification, are typically solved using discriminative methods. So you might be wondering \"what is generative modeling?\".\n",
        "\n",
        "To understand what generative modelling is, let us compare and contrast it with disciminiative modelling. Specifically, let us consider the task of modelling data from two different classes. \n",
        "\n",
        "**Discriminative:** In this case, we are interested in learning a probability distibution $p(y|x)$, i.e., the probablity of the class $y$ being either 0 or 1 given an example $x$. For any example $x$, we can determine whether it is more likely to be from class 0 or class 1, and draw a corresponding decission boundary where $p(y = 0|x) = p(y = 1|x)$. \n",
        "\n",
        "**Generative:** Here, we are interested in learning the probability distribution $p(x|y)$, i.e., the probability of observing some data $x$ given that it is from class $y$. We might also be interested in learning the probability distribution $p(x)$ which is the probability of observing $x$ in either of the classes. *The cool thing about generative modeling is that if we can sample $x \\sim p(x|y)$ or $x \\sim p(x)$ we can generate new unseen examples*. \n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/0*TXI_h4llG-SmdwYY.png\" width=\"60%\" />\n",
        "\n",
        "*In the picture above ([source](https://betterprogramming.pub/generative-vs-discriminative-models-d26def8fd64a_)), red and blue dots represent examples ($x$) from classes $y = 0$ and $y = 1$, respectively. The dashed black line shows the decision boundary in the diciminative case. In the generative case, the light red and blue ovals show the areas where $p(y = 0|x)$ and $p(y = 1|x)$ are large, respectively.*\n",
        "\n",
        "---\n",
        "\n",
        "#### **Generative and Discriminative Models are Two Sides of the Same Coin**\n",
        "\n",
        "From Bayes' rule $$p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$ we can see that the discriminative model $p(y|x)$ and the generative model $p(x|y)$ are very closely linked. If we know $p(x)$ and $p(y)$ then we can convert between a generative and a discriminative model. However, as we will see in the next section, this isn't as easy as it might seem at first glance."
      ],
      "metadata": {
        "id": "rQ5uDyDsjIxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generative Models + NNs = Deep Generative Models**"
      ],
      "metadata": {
        "id": "Ie2YXVWR4ItU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've discussed what a generative model is, we can answer the question \"What is a **deep** generative model?\". In this case, the answer is simple! A deep generative model is a generative model in which either $p_\\theta (x)$ or $p_\\theta (x|y)$ are represeented by (deep) neural networks (with paramters $\\theta$)!\n",
        "\n",
        "To be more concrete, a deep generative model is a neural network that allows us to sample $x$ from the distribution $p_\\theta(x)$ (or $p_\\theta(x|y)$). This is often done by sampling random noise $z$ and using that as the input of the NN ‚Äì in this case the output of the NN is a sample $x$. Some deep generative models also allow us to evaluate $p_\\theta(x)$ for a given example $x$, i.e., they allow us to measure the  probability of observing a particular example. \n",
        "\n",
        "#### **The Challenge of Deep Generative Models**\n",
        "\n",
        "*The central problem of deep generative models is that we do not know how to write down the distribution $p(x)$.* \n",
        "\n",
        "Consider, for example, building a generative model for images of cats. What do you think that the true distribution of such images is? How would you write that down mathematically? These are very difficult questions for humans to answer because images are very high dimensional and it is difficult for us to reason about high dimmensional spaces. \n",
        "\n",
        "The distribtuion $p_\\theta(x|y)$ is similarly high dimensional and difficult for use to describe, so we are not saved by considering the conditional model. (This should not come as a surprise, since we know that $p_\\theta(x)$ and $p_\\theta(x|y)$ are closely tied together via Bayes' rule!)\n",
        "\n",
        "**Why do we need to write down $p_\\theta(x)$?** We said above that we would train a neural network to allow use to draw samples from $p_\\theta(x)$, so if we don't need to evaluate the probability of those samples, why do we need to worry about writing down $p_\\theta(x)$? Unfortunately, we need to **train** our model! If we don't train the model, we have no way of ensuring that the samples we draw actually come from the distribution $p_\\theta(x)$! \n",
        "\n",
        "**How do we train our deep generative model?** From the probabilistic perspective, there is really only one way to train our model: we want to maximise $p_\\theta(x)$ for our observed data. In practice, we will instead minimise (using SGD on the weights $\\theta$) the average *negative log-likelihood* (NLL): $$ \\mathcal{L}_\\text{NLL} = -\\frac{1}{N} \\sum_{n=1}^N \\log p_\\theta(x_n),$$\n",
        "where $\\{x_n\\}_{n=1}^N$ is our training dataset. Thus, we need to be able to evaluate $p(x_n)$. "
      ],
      "metadata": {
        "id": "BDTH1IqojNmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Other Types of Deep Generative Models**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bt089Bkpjb_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we will be focusing on Denoising Diffusion Models in this practical, it is certainly worth keeping in mind that there are many other kinds of deep generative models. Different kinds of models make different assumptions with different pros and cons. Fundamentally, they all solve the problem of calculating $p(x)$ in different ways. Some common deep generative models include:\n",
        "\n",
        "1. Autoregressive models,\n",
        "2. Variational Autoencoders (VAEs),\n",
        "3. Normalizing Flows (NFs),\n",
        "4. Energy-based Models (EBMs), and\n",
        "5. Generative Adversarial Neworks (GANs)"
      ],
      "metadata": {
        "id": "uh_6KQEG2BLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **[Optional] Extra reading on other deep generative models**"
      ],
      "metadata": {
        "id": "A32CACfMw6Jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoregressive models** make the assumption that the probability distribution over a $D$ dimensional observation $\\mathbf{x}$ factorises as $$ p(\\mathbf{x}) = p(x_1) \\prod_{d=1}^{D-1} p(x_{d+1}|x_{d},...,x_1), $$ where $x_d$ is the $d^{th}$ element of $\\mathbf{x}$. This assumption allows us to choose simple distributions for each $p(x_d|...)$ but still have a complex overall distribution for $p(\\mathbf{x})$. However, these models are very expensive to train and sample from due to the conditional structure. Furthermore, it is not clear what the correct ordering of the dimmensions of $\\mathbf{x}$ is. Nevertheless, autoregressive models have seen huge success ‚Äì a prime example being [WaveNet](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)!\n",
        "\n",
        "[TODO: write 1 paragraph summaries for VAEs, NFs, EBMs, and GANs]"
      ],
      "metadata": {
        "id": "cL7moBbQxDou"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9NW58_3hAg2"
      },
      "source": [
        "## **Denoising Diffusion Models**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Denoising diffusion models avoid the problem of estimating $p_\\theta(x)$ by instead estimating the *score function* $\\nabla_x \\log p_\\theta(x)$, i.e., the gradient of the log-likelihood with respect to the observed data $x$. \n",
        "It is because of the importance of the score function that denoising diffusion models are also known as *score-based generative models*.\n",
        "\n",
        "**Note.** The score function $\\nabla_x \\log p_\\theta(x)$ is *not* the same as the gradient of the log-likelihood w.r.t the parameters of the model $\\theta$: $\\nabla_\\theta \\log p_\\theta(x)$, which we would use to train other deep generative models such as NFs and autoregressive models. $\\nabla_\\theta \\log p_\\theta(x)$ tells us how to change the parameters of the model to increase the likelihood, while $\\nabla_x \\log p_\\theta(x)$ tells us how to change the data itself!"
      ],
      "metadata": {
        "id": "YFLXagxPGFC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Score Function Illustration**\n",
        "\n"
      ],
      "metadata": {
        "id": "RHMaBPgTkcxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get some intuition for what the score function is, and how we can use it to create samples from a desired distribution, lets consider a simple bi-modal distribution $$ p(\\mathbf{x}) = 0.5 \\cdot \\mathcal{N}\\left(\\mathbf{x}\\, \\middle|\\, \\mathbf{\\mu}=\\left[ {\\begin{array}{cc}\n",
        "    0.8 \\\\\n",
        "    3.2 \\\\\n",
        "  \\end{array} } \\right], \\Sigma = \\left[ {\\begin{array}{cc}\n",
        "    0.8 & -0.8 \\\\\n",
        "    -0.8 & 2.0 \\\\\n",
        "  \\end{array} } \\right]\\right) + 0.5 \\cdot \\mathcal{N}\\left(\\mathbf{x}\\, \\middle|\\, \\left[ {\\begin{array}{cc}\n",
        "    -1.3 \\\\\n",
        "    -2.7 \\\\\n",
        "  \\end{array} } \\right], \\left[ {\\begin{array}{cc}\n",
        "    1.5 & 0.75 \\\\\n",
        "    0.75 & 1.5 \\\\\n",
        "  \\end{array} } \\right]\\right). $$\n",
        "\n",
        "  We can easily implement this density function in `jax` using the [`Distrax`](https://github.com/deepmind/distrax) library: "
      ],
      "metadata": {
        "id": "Fb_Y_sMMGKm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dist_1 = distrax.MultivariateNormalFullCovariance([.8, 3.2], covariance_matrix=[[.8, -.8], [-.8, 2.]])\n",
        "dist_2 = distrax.MultivariateNormalFullCovariance([-1.3, -2.7], covariance_matrix=[[1.5, .75], [.75, 1.5]])\n",
        "density_fn = lambda x: 0.5*jnp.exp(dist_1.log_prob(x.astype(jnp.float32))) + 0.5*jnp.exp(dist_2.log_prob(x.astype(jnp.float32)))"
      ],
      "metadata": {
        "id": "dnZ27KpY7lnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Task:** Use `jax`'s `grad` transform to implement the score function."
      ],
      "metadata": {
        "id": "0oMDEzIt-BHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_fn =  # YOUR SOLUTION GOES HERE "
      ],
      "metadata": {
        "id": "UXO6zUal-RwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!') \n",
        "score_fn = jax.grad(lambda x: jnp.log(density_fn(x)))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3wwpRQ2G-V6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the score function for $p(x)$, we can use it to take randomly sampled noise and transform it into samples from $p(x)$. The procedure is simple: start with an initial random guess $x_T$, and then for $T$ *time*steps calculate $$ x_{t-1} = x_{t} + \\lambda \\cdot \\nabla_x \\log p(x), $$\n",
        "until we arrive at $x_0$, which we hope will be a sample from $p(x)$.\n",
        "Here $\\lambda$ is a step size parameter which controlls how big a change we make at each timestep.\n",
        "\n",
        "**Group Task:**\n",
        "\n",
        "1. Using the sliders below, experiment with randomly choosing different coordinates for $\\mathbf{x}$, as well as different numbers of timesteps and step sizes. \n",
        "2. Compare your initial coordinates $\\mathbf{x}_T$ (red crosses) with the final coordinates $\\mathbf{x}_0$ (cyan crosses). Which are more similar to the coordinates directly sampled from $p(\\mathbf{x})$ (black circles)? \n",
        "3. Discuss amongst yourselves to make sure that this behaviour makes sense."
      ],
      "metadata": {
        "id": "vt0w6fEk_R0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Two Gaussians Score Function\n",
        "from matplotlib import cm\n",
        "\n",
        "x0 =  0.1 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "x1 =  -4.9 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "x = jnp.array([x0, x1], dtype=jnp.float32)\n",
        "\n",
        "num_steps = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "step_size = 0.2 #@param {type:\"slider\", min:0.1, max:1, step:0.05}\n",
        "\n",
        "\n",
        "# Make plots of the density p(x)\n",
        "X0 = jnp.arange(-5, 5.1, 0.25)\n",
        "X1 = jnp.arange(-5, 5.1, 0.25)\n",
        "X0, X1 = jnp.meshgrid(X0, X1)\n",
        "\n",
        "Xs = jnp.concatenate(\n",
        "    [X0.reshape(-1, 1), X1.reshape(-1, 1)], axis=1\n",
        ")\n",
        "Z = jax.vmap(density_fn)(Xs).reshape(X1.shape)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.plot_surface(X0, X1, Z, cmap=cm.coolwarm,\n",
        "                linewidth=0, alpha=0.4, antialiased=False)\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.contourf(X0, X1, Z, cmap=cm.coolwarm,\n",
        "            alpha=0.4, antialiased=False)\n",
        "\n",
        "\n",
        "# Plot some samples from the true data distribution\n",
        "key1, key2 = jax.random.split(jax.random.PRNGKey(42)) \n",
        "samples1, log_probs1 = dist_1.sample_and_log_prob(seed=key1, sample_shape=(25))\n",
        "samples2, log_probs2 = dist_2.sample_and_log_prob(seed=key2, sample_shape=(25))  \n",
        "\n",
        "log_probs = jnp.concatenate([log_probs1, log_probs2])\n",
        "probs = 0.5*jnp.exp(log_probs)\n",
        "samples = jnp.concatenate([samples1, samples2])\n",
        "\n",
        "ax1.scatter(samples[:, 0], samples[:, 1], probs, c='k', marker='o', alpha=0.5)\n",
        "ax2.scatter(samples[:, 0], samples[:, 1], c='k', marker='o', alpha=0.5)\n",
        "\n",
        "\n",
        "# Plot the trajectory of the sample over time\n",
        "ax1.scatter(x[0], x[1], density_fn(x), c='r', marker='x', s=75)\n",
        "ax2.scatter(x[0], x[1], c='r', marker='x', s=75)\n",
        "\n",
        "for step in range(num_steps):\n",
        "    grad = score_fn(x)\n",
        "    x = x + step_size*grad\n",
        "\n",
        "    color = 'k' if step < num_steps - 1 else 'c'\n",
        "    ax1.scatter(x[0], x[1], density_fn(x), c=color, marker='x', s=75)\n",
        "    ax2.scatter(x[0], x[1], c=color, marker='x', s=75)  \n",
        "\n",
        "\n",
        "ax1.set_ylim(-5, 5)\n",
        "ax1.set_xlim(-5, 5)\n",
        "ax1.set_zlim(0, 0.1)\n",
        "\n",
        "ax2.set_ylim(-5, 5)\n",
        "ax2.set_xlim(-5, 5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9bIMuhCXGZ7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **[Optional] Connections to EBM, VAEs, and Autoregressive Models**"
      ],
      "metadata": {
        "id": "GMrkjFUbfQjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[TODO]"
      ],
      "metadata": {
        "id": "r-aldBFnxNRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Diffusion**"
      ],
      "metadata": {
        "id": "hL1UER25kLki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50IJPZEUbUXW"
      },
      "outputs": [],
      "source": [
        "# TODO: turn into coding task\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return jnp.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "# TODO: plot this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr4ui0FMbtCf"
      },
      "outputs": [],
      "source": [
        "# TODO: add explanations for this code! \n",
        "\n",
        "TIMESTEPS = 200\n",
        "\n",
        "# define beta schedule\n",
        "betas = linear_beta_schedule(timesteps=TIMESTEPS)\n",
        "\n",
        "# define alphas \n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = jnp.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = jnp.concatenate((jnp.array([1.0]), alphas_cumprod[:-1]))\n",
        "sqrt_recip_alphas = jnp.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = jnp.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = jnp.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    batch_size = t.shape[0]\n",
        "    out = a[..., t]\n",
        "    return jnp.reshape(out, (batch_size, *((1,) * (len(x_shape) - 1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGXAWMT3ewNL"
      },
      "outputs": [],
      "source": [
        "# forward diffusion\n",
        "def q_sample(x_start, t, noise):\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
        "\n",
        "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baWScJkCggoO"
      },
      "outputs": [],
      "source": [
        "def get_noisy_image(image, t, key):\n",
        "    x_start = jnp.asarray(image, dtype=jnp.float32)[jnp.newaxis, ...]\n",
        "    x_start = x_start / 255.  # normalize the images to [0, 1]\n",
        "    x_start = (x_start * 2.) - 1.  # convert range to [-1, 1]\n",
        "\n",
        "    # add noise\n",
        "    noise = jax.random.normal(key, x_start.shape)\n",
        "    x_noisy = q_sample(x_start, t, noise)\n",
        "\n",
        "    # turn back into PIL image\n",
        "    x_noisy = (x_noisy + 1.) / 2.\n",
        "    x_noisy = x_noisy * 255.\n",
        "    img_array = np.array(x_noisy).astype(jnp.uint8)[0]\n",
        "    noisy_image = Image.fromarray(img_array)\n",
        "\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97xnkaT2VjG9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# TODO: find better image... Indaba themed?\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDfJTyPXbjOE"
      },
      "outputs": [],
      "source": [
        "get_noisy_image(image, jnp.array([40]), jax.random.PRNGKey(42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYWNWzhoivw3"
      },
      "outputs": [],
      "source": [
        "imgs = [get_noisy_image(image, jnp.array([t]), jax.random.PRNGKey(0)) for t in [0, 50, 100, 150, 199]]\n",
        "\n",
        "num_cols = len(imgs)\n",
        "fig, axs = plt.subplots(figsize=(200,200), nrows=1, ncols=num_cols, squeeze=False)\n",
        "for idx, img in enumerate(imgs):\n",
        "    ax = axs[0, idx]\n",
        "    ax.imshow(np.asarray(img))\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Diffusion Models in Practice**"
      ],
      "metadata": {
        "id": "R8GjQPN2iNHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The dataset**"
      ],
      "metadata": {
        "id": "oTveZRSCh9KK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehc1dfURbh0K"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# We are getting the labels only for the pruposes of exploring the data,\n",
        "# we won't use them to train our models (or will we?).\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# text_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show 25 randomly selected images at a time\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    img_index = np.random.randint(0, 50000)\n",
        "    plt.imshow(train_images[img_index], cmap=\"gray_r\")\n",
        "    # plt.xlabel(text_labels[train_labels[img_index]])"
      ],
      "metadata": {
        "id": "XHIAIoKGP0ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoEHx-a8dbsH"
      },
      "outputs": [],
      "source": [
        "train_data = np.expand_dims(train_images, axis=3) # add a channel dim\n",
        "train_data = train_data.astype('float32') # convert to float32\n",
        "train_data = (train_data - 127.5) / 127.5 # normalize the images to [-1, 1]\n",
        "# TODO: move all of the above into a MAP statement?\n",
        "BATCH_SIZE = 128\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_data).cache().repeat().shuffle(BATCH_SIZE*10).batch(BATCH_SIZE)\n",
        "train_dataset = iter(tensorflow_datasets.as_numpy(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Building the NN**"
      ],
      "metadata": {
        "id": "PAzSULmrh4_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfnt64ZKlADo"
      },
      "outputs": [],
      "source": [
        "class SinusoidalTimeEmbeddings(hk.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def __call__(self, time):\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = jnp.log(10000) / (half_dim - 1)\n",
        "        embeddings = jnp.exp(jnp.arange(half_dim) * -embeddings)\n",
        "        embeddings = time[:, jnp.newaxis] * embeddings[jnp.newaxis, :]\n",
        "        embeddings = jnp.concatenate((jnp.sin(embeddings), jnp.cos(embeddings)), axis=-1)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sMtW7NKrEQy"
      },
      "outputs": [],
      "source": [
        "class Block(hk.Module):\n",
        "    def __init__(self, dim_out, groups = 8):\n",
        "        super().__init__()\n",
        "        self.proj = hk.Conv2D(dim_out, kernel_shape=3, padding=(1, 1))\n",
        "        self.norm = hk.GroupNorm(groups)\n",
        "        self.act = jax.nn.silu\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class ResnetBlock(hk.Module):\n",
        "    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n",
        "    \n",
        "    def __init__(self, dim_out, groups=8, change_dim=False):\n",
        "        super().__init__()\n",
        "        self.mlp = hk.Sequential([jax.nn.silu, hk.Linear(dim_out)])\n",
        "        self.block1 = Block(dim_out, groups=groups)\n",
        "        self.block2 = Block(dim_out, groups=groups)\n",
        "        self.res_conv = hk.Conv2D(dim_out, kernel_shape=1, padding=(0, 0)) if change_dim else lambda x: x\n",
        "\n",
        "    def __call__(self, x, time_emb):\n",
        "        h = self.block1(x)\n",
        "\n",
        "        time_emb = self.mlp(time_emb)\n",
        "        h = time_emb[:, jnp.newaxis, jnp.newaxis] + h\n",
        "\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV7FCh4xsr8u"
      },
      "outputs": [],
      "source": [
        "def Upsample(dim):\n",
        "    return hk.Conv2DTranspose(dim, kernel_shape=4, stride=2)\n",
        "\n",
        "def Downsample(dim):\n",
        "    return hk.Conv2D(dim, kernel_shape=4, stride=2, padding=(1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sesgVpsthotg"
      },
      "outputs": [],
      "source": [
        "# TODO: add picture\n",
        "\n",
        "class Unet(hk.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        dim_mults=(1, 2, 4,),\n",
        "        channels=3,\n",
        "        resnet_block_groups=7,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # determine dimensions\n",
        "        init_dim = dim // 3 * 2\n",
        "        self.init_conv = hk.Conv2D(init_dim, kernel_shape=7, padding=(3, 3))\n",
        "        \n",
        "        # time embeddings\n",
        "        time_dim = dim * 4\n",
        "        self.time_mlp = hk.Sequential([\n",
        "            SinusoidalTimeEmbeddings(dim),\n",
        "            hk.Linear(time_dim),\n",
        "            jax.nn.gelu,\n",
        "            hk.Linear(time_dim),\n",
        "        ])\n",
        "\n",
        "        # layers\n",
        "        self.downs = []\n",
        "        self.ups = []\n",
        "        dims = list(map(lambda m: dim * m, dim_mults))\n",
        "\n",
        "        for ind, stage_dim in enumerate(dims):\n",
        "            is_last = ind >= len(dims) - 1\n",
        "\n",
        "            self.downs.append([\n",
        "                ResnetBlock(stage_dim, groups=resnet_block_groups, change_dim=True),\n",
        "                ResnetBlock(stage_dim, groups=resnet_block_groups),\n",
        "                Downsample(stage_dim) if not is_last else lambda x: x,\n",
        "            ])\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = ResnetBlock(mid_dim, groups=resnet_block_groups)\n",
        "        self.mid_block2 = ResnetBlock(mid_dim, groups=resnet_block_groups)\n",
        "\n",
        "        rev_dims = list(reversed(dims))\n",
        "        for ind, stage_dim in enumerate(rev_dims):\n",
        "            is_last = ind >= len(rev_dims) - 1\n",
        "\n",
        "            # TODO: turn into coding task:\n",
        "            self.ups.append([\n",
        "                ResnetBlock(stage_dim, groups=resnet_block_groups, change_dim=True),\n",
        "                ResnetBlock(stage_dim, groups=resnet_block_groups),\n",
        "                Upsample(stage_dim) if not is_last else lambda x: x,\n",
        "            ])\n",
        "\n",
        "        self.final_block = ResnetBlock(dim, groups=resnet_block_groups)\n",
        "        self.final_conv = hk.Conv2D(channels, kernel_shape=1, padding=(0, 0))\n",
        "\n",
        "    def __call__(self, x, time):\n",
        "        x = self.init_conv(x)\n",
        "        t = self.time_mlp(time)\n",
        "\n",
        "        h = []\n",
        "        # downsample\n",
        "        for block1, block2, downsample in self.downs:\n",
        "            x = block1(x, t)\n",
        "            x = block2(x, t)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        # bottleneck\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        # upsample\n",
        "        for block1, block2, upsample in self.ups:\n",
        "            # TODO: turn into coding task:\n",
        "            x = jnp.concatenate((x, h.pop()), axis=-1)\n",
        "            x = block1(x, t)\n",
        "            x = block2(x, t)\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = self.final_block(x, t)\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Training**"
      ],
      "metadata": {
        "id": "E2-yrQShiX2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_forward_fn(dim, channels, dim_mults=None, resnet_block_groups=7):\n",
        "    if dim_mults is None:\n",
        "        dim_mults=(1, 2, 4,)\n",
        "\n",
        "    def forward_fn(x, time):\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        model = Unet(\n",
        "            dim, dim_mults=dim_mults, channels=channels,\n",
        "            resnet_block_groups=resnet_block_groups,\n",
        "        )\n",
        "\n",
        "        return model(x, time)\n",
        "\n",
        "    return forward_fn"
      ],
      "metadata": {
        "id": "Nxux7w-oO7_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 3e-4\n",
        "IMAGE_SIZE = 28\n",
        "CHANNELS = 1\n",
        "\n",
        "# initialise model\n",
        "init_rng = jax.random.PRNGKey(42)\n",
        "forward_fn = hk.transform(build_forward_fn(dim=IMAGE_SIZE, channels=CHANNELS))\n",
        "forward_fn = hk.without_apply_rng(forward_fn)\n",
        "\n",
        "dummy_input = jnp.ones((1, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "params = forward_fn.init(init_rng, dummy_input, jnp.array([0]))\n",
        "\n",
        "# set up the optimiser\n",
        "optimiser = optax.adam(LR)\n",
        "opt_state = optimiser.init(params)"
      ],
      "metadata": {
        "id": "6FhydE4yLoBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add task for deriving how this loss relates to NLL?\n",
        "# Bonus task: actually implement NLL to show that they are the same?\n",
        "@jax.jit\n",
        "def loss_fn(params, x_batch, t, noise):\n",
        "    x_noisy = q_sample(x_start=x_batch, t=t, noise=noise)\n",
        "    predicted_noise = forward_fn.apply(params, x_noisy, t)\n",
        "\n",
        "    batch_loss = jnp.mean((predicted_noise - noise)**2)\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "@jax.jit\n",
        "def update(params, opt_state, batch, t, noise):\n",
        "  # get data neded for training\n",
        "  loss, grads = jax.value_and_grad(loss_fn)(params, batch, t, noise)\n",
        "  updates, opt_state = optimiser.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state, loss\n",
        "\n",
        "# TODO: turn into coding task:\n",
        "@partial(jax.jit, static_argnums=4)\n",
        "def sample_iteration(params, key, x, t, add_noise=True):\n",
        "    betas_t = extract(betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
        "    \n",
        "    # Equation 11 in the paper\n",
        "    # Use our model (noise predictor) to predict the mean\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * forward_fn.apply(params, x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
        "    noise = jax.random.normal(key, x.shape)\n",
        "\n",
        "    # Algorithm 2 line 4:\n",
        "    return model_mean + jnp.sqrt(posterior_variance_t) * noise \n",
        "\n",
        "# Algorithm 2 but save all images:\n",
        "def sample(params, key, image_size, batch_size=16, channels=3):\n",
        "    shape = (batch_size, image_size, image_size, channels)\n",
        "\n",
        "    img_key, key = jax.random.split(key, num=2)\n",
        "    # start from pure noise (for each example in the batch)\n",
        "    img = jax.random.normal(img_key, shape)\n",
        "    imgs = []\n",
        "    \n",
        "    for i in tqdm(reversed(range(0, TIMESTEPS)), desc='sampling loop time step', total=TIMESTEPS):\n",
        "        noise_key, key = jax.random.split(key, num=2)\n",
        "        img = sample_iteration(params, noise_key, img, jnp.full((batch_size,), i), i != 0)\n",
        "        imgs.append(img)\n",
        "\n",
        "    return imgs"
      ],
      "metadata": {
        "id": "Cs065rgHV5WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS = 2501\n",
        "LOG_EVERY = 100\n",
        "\n",
        "key = jax.random.PRNGKey(42)\n",
        "\n",
        "# TODO: fix memory leak\n",
        "\n",
        "# Training & evaluation loop.\n",
        "best_loss = jnp.inf\n",
        "for step in tqdm(range(STEPS)):\n",
        "    key, noise_key, time_key, sample_key = jax.random.split(key, num=4)\n",
        "\n",
        "    x_batch = next(train_dataset)\n",
        "    batch_size = x_batch.shape[0]\n",
        "\n",
        "    t = jax.random.randint(time_key, (batch_size,), 0, TIMESTEPS)\n",
        "    noise = jax.random.normal(noise_key, x_batch.shape)\n",
        "    params, opt_state, loss = update(params, opt_state, x_batch, t, noise)\n",
        "    # TODO: add losses to TQDM\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_params = params\n",
        "        best_loss = loss\n",
        "        best_step = step\n",
        "\n",
        "    if step % LOG_EVERY == 0:\n",
        "        print(f'{step:4} - {loss:.4f} \\t ({best_step:4} - {best_loss:.4f})')"
      ],
      "metadata": {
        "id": "rE7ZJZN3lQ13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = sample(best_params, key, IMAGE_SIZE, 32, CHANNELS)"
      ],
      "metadata": {
        "id": "3-UJs5vQQ5ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show 25 randomly selected images at a time\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    img_index = np.random.randint(0, 50000)\n",
        "    plt.imshow(samples[-1][i][:, :, 0], cmap=\"gray_r\")"
      ],
      "metadata": {
        "id": "5EeRLL1AVNKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.animation as animation\n",
        "\n",
        "sample_index = 32\n",
        "\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for i in range(TIMESTEPS):\n",
        "    im = plt.imshow(samples[i][sample_index][:, :, 0], cmap=\"gray_r\", animated=True)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    ims.append([im])\n",
        "\n",
        "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=5000)\n",
        "plt.close()\n",
        "\n",
        "HTML(animate.to_html5_video())"
      ],
      "metadata": {
        "id": "JXz8o2uoV3uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Guided diffusion**\n",
        "\n",
        "[TODO] explain guided diffusion "
      ],
      "metadata": {
        "id": "QVAuiHsXfNJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Excercises** \n",
        "\n",
        "1. [Beginner] Try scale up to FashionMNIST. Hint, adding attention (and ConvNext?) might help.\n",
        "2. [Intermediate] Add label information to make a conditional generative model $p(x|y)$.\n",
        "3. [Advanced] Implement classifier free guidance."
      ],
      "metadata": {
        "id": "QISTyJf24hps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Code that might be useful for scaling up the model... not sure yet\n",
        "\n",
        "# Residual(PreNorm(Attention(dim)))\n",
        "\n",
        "class Attention(hk.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head**-0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = hk.Conv2D(hidden_dim * 3, kernel_shape=1, padding=(0, 0), with_bias=False)\n",
        "        self.to_out = hk.Conv2D(dim, kernel_shape=1, padding=(0, 0))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        b, h, w, c = x.shape\n",
        "        qkv = jnp.array_split(self.to_qkv(x), 3, axis=-1)\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b x y (h d) -> b h d (x y)\", h=self.heads), qkv  # c = (h d), i = (x y)\n",
        "        )\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = contract(\"b h d i, b h d j -> b h i j\", q, k)\n",
        "        # Softmax trick to avoid numerical issues\n",
        "        sim = sim - jax.lax.stop_gradient(jnp.argmax(sim, axis=-1, keepdims=True))\n",
        "        attn = jax.nn.softmax(sim, axis=-1)\n",
        "\n",
        "        out = contract(\"b h i j, b h d j -> b h i d\", attn, v)\n",
        "        out = rearrange(out, \"b h (x y) d -> b x y (h d)\", x=h, y=w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class PreNorm(hk.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = hk.GroupNorm(1)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)\n",
        "\n",
        "class Residual(hk.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def __call__(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x"
      ],
      "metadata": {
        "id": "u1Gu0co04uOR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3YG7QOZD-B"
      },
      "source": [
        "## Conclusion\n",
        "**Summary:**\n",
        "\n",
        "[Summary of the main points/takeaways from the prac.]\n",
        "\n",
        "**Next Steps:** \n",
        "\n",
        "[Next steps for people who have completed the prac, like optional reading (e.g. blogs, papers, courses, youtube videos). This could also link to other pracs.]\n",
        "\n",
        "**Appendix:** \n",
        "\n",
        "[Anything (probably math heavy stuff) we don't have space for in the main practical sections.]\n",
        "\n",
        "**References:** \n",
        "\n",
        "Much of this material was adapted from and inspired by [The Annotated Diffusion Model ü§ó](https://huggingface.co/blog/annotated-diffusion).\n",
        "\n",
        "For other practicals from the Deep Learning Indaba, please visit [here](https://github.com/deep-learning-indaba/indaba-pracs-2022)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ndpYE50BpG"
      },
      "source": [
        "## Feedback\n",
        "\n",
        "Please provide feedback that we can use to improve our practicals in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIZvkhfRz9Jz"
      },
      "outputs": [],
      "source": [
        "#@title Generate Feedback Form. (Run Cell)\n",
        "from IPython.display import HTML\n",
        "HTML(\n",
        "\"\"\"\n",
        "<iframe \n",
        "\tsrc=\"https://forms.gle/bvLLPX74LMGrFefo9\",\n",
        "  width=\"80%\" \n",
        "\theight=\"1200px\" >\n",
        "\tLoading...\n",
        "</iframe>\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oglV4kHMWnIN"
      },
      "source": [
        "<img src=\"https://baobab.deeplearningindaba.com/static/media/indaba-logo-dark.d5a6196d.png\" width=\"50%\" />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6EqhIg1odqg0",
        "-ZUp8i37dFbU",
        "7SrT6swYgCm9",
        "M0xpQUsjlfnY",
        "T6UsuU1ImRTs",
        "v5OB2KDJp3hR",
        "0mfHQOmE4Agg"
      ],
      "name": "deep_generative_models.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "145833166d986a8417df3c7acb65d917d84b716b5a452e57fcacdc66f1a168c9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}